{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Strings using substring\n",
    "Let us understand how to extract strings from main string using `substring` function in Pyspark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If we are processing **fixed length columns** then we use `substring` to extract the information.\n",
    "* Here are some of the examples for **fixed length columns** and the use cases for which we typically extract information..\n",
    "* 9 Digit Social Security Number. We typically extract last 4 digits and provide it to the tele verification applications..\n",
    "* 16 Digit Credit Card Number. We typically use first 4 digit number to identify Credit Card Provider and last 4 digits for the purpose of tele verification.\n",
    "* Data coming from MainFrames systems are quite often fixed length. We might have to extract the information and store in multiple columns.\n",
    "* `substring` function takes 3 arguments, **column**, **position**, **length**. We can also provide position from the end by passing negative value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start spark context for this Notebook so that we can execute the code provided. You can sign up for our [10 node state of the art cluster/labs](https://labs.itversity.com/plans) to learn Spark SQL using our unique integrated LMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    config('spark.ui.port', '0'). \\\n",
    "    config(\"spark.sql.warehouse.dir\", f\"/user/{username}/warehouse\"). \\\n",
    "    enableHiveSupport(). \\\n",
    "    appName(f'{username} | Python - Processing Column Data'). \\\n",
    "    master('yarn'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are going to use CLIs, you can use Spark SQL using one of the 3 approaches.\n",
    "\n",
    "**Using Spark SQL**\n",
    "\n",
    "```\n",
    "spark2-sql \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```\n",
    "\n",
    "**Using Scala**\n",
    "\n",
    "```\n",
    "spark2-shell \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```\n",
    "\n",
    "**Using Pyspark**\n",
    "\n",
    "```\n",
    "pyspark2 \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Here is how we typically take care of getting substring from the main string using Python. We pass index and length to extract the substring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"Hello World\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts first 5 characters from the string\n",
    "s[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts characters from 2nd to 4th (3 characters). \n",
    "# Second argument is length of the string that need to be considered.\n",
    "s[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [('X', )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(l, \"dummy STRING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can use `substring` function to extract substring from main string using Pyspark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import substring, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Function takes 3 arguments\n",
    "# First argument is a column from which we want to extract substring.\n",
    "# Second argument is the character from which string is supposed to be extracted.\n",
    "# Third argument is number of characters from the first argument.\n",
    "df.select(substring(lit(\"Hello World\"), 7, 5)). \\\n",
    "  show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.select(substring(lit(\"Hello World\"), -5, 5)). \\\n",
    "  show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks - substring\n",
    "\n",
    "Let us perform few tasks to extract information from fixed length strings.\n",
    "* Create a list for employees with name, ssn and phone_number.\n",
    "* SSN Format **3 2 4** - Fixed Length with 11 characters\n",
    "* Phone Number Format - Country Code is variable and remaining phone number have 10 digits:\n",
    " * Country Code - one to 3 digits\n",
    " * Area Code - 3 digits\n",
    " * Phone Number Prefix - 3 digits\n",
    " * Phone Number Remaining - 4 digits\n",
    " * All the 4 parts are separated by spaces\n",
    "* Create a Dataframe with column names name, ssn and phone_number\n",
    "* Extract last 4 digits from the phone number.\n",
    "* Extract last 4 digits from SSN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees = [(1, \"Scott\", \"Tiger\", 1000.0, \n",
    "                      \"united states\", \"+1 123 456 7890\", \"123 45 6789\"\n",
    "                     ),\n",
    "                     (2, \"Henry\", \"Ford\", 1250.0, \n",
    "                      \"India\", \"+91 234 567 8901\", \"456 78 9123\"\n",
    "                     ),\n",
    "                     (3, \"Nick\", \"Junior\", 750.0, \n",
    "                      \"united KINGDOM\", \"+44 111 111 1111\", \"222 33 4444\"\n",
    "                     ),\n",
    "                     (4, \"Bill\", \"Gomes\", 1500.0, \n",
    "                      \"AUSTRALIA\", \"+61 987 654 3210\", \"789 12 6118\"\n",
    "                     )\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employeesDF = spark. \\\n",
    "    createDataFrame(employees,\n",
    "                    schema=\"\"\"employee_id INT, first_name STRING, \n",
    "                    last_name STRING, salary FLOAT, nationality STRING,\n",
    "                    phone_number STRING, ssn STRING\"\"\"\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employeesDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import substring, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "employeesDF. \\\n",
    "    select(\"employee_id\", \"phone_number\", \"ssn\"). \\\n",
    "    withColumn(\"phone_last4\", substring(col(\"phone_number\"), -4, 4).cast(\"int\")). \\\n",
    "    withColumn(\"ssn_last4\", substring(col(\"ssn\"), 8, 4).cast(\"int\")). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employeesDF. \\\n",
    "    select(\"employee_id\", \"phone_number\", \"ssn\"). \\\n",
    "    withColumn(\"phone_last4\", substring(col(\"phone_number\"), -4, 4).cast(\"int\")). \\\n",
    "    withColumn(\"ssn_last4\", substring(col(\"ssn\"), 8, 4).cast(\"int\")). \\\n",
    "    printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 2",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
