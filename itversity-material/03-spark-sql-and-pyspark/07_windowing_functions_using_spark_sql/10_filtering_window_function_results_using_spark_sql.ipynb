{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering - Window Function Results\n",
    "\n",
    "Let us understand how to filter on top of results of Window Functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start spark context for this Notebook so that we can execute the code provided. You can sign up for our [10 node state of the art cluster/labs](https://labs.itversity.com/plans) to learn Spark SQL using our unique integrated LMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val username = System.getProperty(\"user.name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val username = System.getProperty(\"user.name\")\n",
    "val spark = SparkSession.\n",
    "    builder.\n",
    "    config(\"spark.ui.port\", \"0\").\n",
    "    config(\"spark.sql.warehouse.dir\", s\"/user/${username}/warehouse\").\n",
    "    enableHiveSupport.\n",
    "    appName(s\"${username} | Spark SQL - Windowing Functions\").\n",
    "    master(\"yarn\").\n",
    "    getOrCreate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are going to use CLIs, you can use Spark SQL using one of the 3 approaches.\n",
    "\n",
    "**Using Spark SQL**\n",
    "\n",
    "```\n",
    "spark2-sql \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```\n",
    "\n",
    "**Using Scala**\n",
    "\n",
    "```\n",
    "spark2-shell \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```\n",
    "\n",
    "**Using Pyspark**\n",
    "\n",
    "```\n",
    "pyspark2 \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can use **Window Functions** only in **SELECT** Clause.\n",
    "* If we have to filter based on Window Function results, then we need to use Sub Queries.\n",
    "* Once the query with window functions is defined as sub query, we can apply filter using aliases provided for the Window Functions.\n",
    "\n",
    "Here is the example where we can filter data based on Window Functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "USE itversity_retail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * FROM (\n",
    "  SELECT t.*,\n",
    "    dense_rank() OVER (\n",
    "      PARTITION BY order_date\n",
    "      ORDER BY revenue DESC\n",
    "    ) AS drnk\n",
    "  FROM daily_product_revenue t\n",
    ") q\n",
    "WHERE q.drnk <= 5\n",
    "ORDER BY q.order_date, q.revenue DESC\n",
    "LIMIT 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"SELECT * FROM (\n",
    "  SELECT t.*,\n",
    "    dense_rank() OVER (\n",
    "      PARTITION BY order_date\n",
    "      ORDER BY revenue DESC\n",
    "    ) AS drnk\n",
    "  FROM daily_product_revenue t\n",
    ") q\n",
    "WHERE q.drnk <= 5\n",
    "ORDER BY q.order_date, q.revenue DESC\n",
    "\"\"\").\n",
    "    show(100, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking and Filtering - Recap\n",
    "\n",
    "Let us recap the procedure to get top 5 orders by revenue for each day.\n",
    "\n",
    "* We have our original data in **orders** and **order_items**\n",
    "* We can pre-compute the data and store in a table or create a view with the logic to generate **daily product revenue**\n",
    "* Then, we have to use the view or table or even sub query to compute rank\n",
    "* We can use the query with ranks as sub query to filter so that we can get top 5 products by revenue.\n",
    "* Let us see the overall process in action.\n",
    "\n",
    "Let us come up with the query to compute daily product revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "USE itversity_retail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DESCRIBE orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DESCRIBE order_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT o.order_date,\n",
    "       oi.order_item_product_id,\n",
    "       round(sum(oi.order_item_subtotal), 2) AS revenue\n",
    "FROM orders o JOIN order_items oi\n",
    "ON o.order_id = oi.order_item_order_id\n",
    "WHERE o.order_status IN ('COMPLETE', 'CLOSED')\n",
    "GROUP BY o.order_date, oi.order_item_product_id\n",
    "ORDER BY o.order_date, revenue DESC\n",
    "LIMIT 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us compute the rank for each product with in each date using revenue as criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT q.*,\n",
    "  rank() OVER (\n",
    "    PARTITION BY order_date\n",
    "    ORDER BY revenue DESC\n",
    "  ) AS rnk,\n",
    "  dense_rank() OVER (\n",
    "    PARTITION BY order_date\n",
    "    ORDER BY revenue DESC\n",
    "  ) AS drnk\n",
    "FROM (SELECT o.order_date,\n",
    "        oi.order_item_product_id,\n",
    "        round(sum(oi.order_item_subtotal), 2) AS revenue\n",
    "      FROM orders o JOIN order_items oi\n",
    "      ON o.order_id = oi.order_item_order_id\n",
    "      WHERE o.order_status IN ('COMPLETE', 'CLOSED')\n",
    "      GROUP BY o.order_date, oi.order_item_product_id) q\n",
    "ORDER BY order_date, revenue DESC\n",
    "LIMIT 35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us see how we can filter the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * FROM (SELECT q.*,\n",
    "  dense_rank() OVER (\n",
    "    PARTITION BY order_date\n",
    "    ORDER BY revenue DESC\n",
    "  ) AS drnk\n",
    "FROM (SELECT o.order_date,\n",
    "        oi.order_item_product_id,\n",
    "        round(sum(oi.order_item_subtotal), 2) AS revenue\n",
    "      FROM orders o JOIN order_items oi\n",
    "      ON o.order_id = oi.order_item_order_id\n",
    "      WHERE o.order_status IN ('COMPLETE', 'CLOSED')\n",
    "      GROUP BY o.order_date, oi.order_item_product_id) q) q1\n",
    "WHERE drnk <= 5\n",
    "ORDER BY order_date, revenue DESC\n",
    "LIMIT 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"DESCRIBE daily_product_revenue\").show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * FROM (SELECT dpr.*,\n",
    "  dense_rank() OVER (\n",
    "    PARTITION BY order_date\n",
    "    ORDER BY revenue DESC\n",
    "  ) AS drnk\n",
    "FROM daily_product_revenue AS dpr)\n",
    "WHERE drnk <= 5\n",
    "ORDER BY order_date, revenue DESC\n",
    "LIMIT 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
