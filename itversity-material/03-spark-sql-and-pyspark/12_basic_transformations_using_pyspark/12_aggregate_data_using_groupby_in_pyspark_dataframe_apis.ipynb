{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate data using groupBy\n",
    "\n",
    "Let us go through the details related to aggregations using `groupBy` in Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Here are the APIs which we typically use to group the data using a key. As part of this topic, we will primarily focus on `groupBy`.\n",
    "  * `groupBy`\n",
    "  * `rollup`\n",
    "  * `cube`\n",
    "* Here are the functions which we typically use to perform aggregations.\n",
    "  * `count`\n",
    "  * `sum`, `avg`\n",
    "  * `min`, `max`\n",
    "* If we want to provide aliases to the aggregated fields then we have to use `agg` after `groupBy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start spark context for this Notebook so that we can execute the code provided. You can sign up for our [10 node state of the art cluster/labs](https://labs.itversity.com/plans) to learn Spark SQL using our unique integrated LMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    config('spark.ui.port', '0'). \\\n",
    "    config(\"spark.sql.warehouse.dir\", f\"/user/{username}/warehouse\"). \\\n",
    "    enableHiveSupport(). \\\n",
    "    appName(f'{username} | Python - Basic Transformations'). \\\n",
    "    master('yarn'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are going to use CLIs, you can use Spark SQL using one of the 3 approaches.\n",
    "\n",
    "**Using Spark SQL**\n",
    "\n",
    "```\n",
    "spark2-sql \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```\n",
    "\n",
    "**Using Scala**\n",
    "\n",
    "```\n",
    "spark2-shell \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```\n",
    "\n",
    "**Using Pyspark**\n",
    "\n",
    "```\n",
    "pyspark2 \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "airtraffic_path = \"/public/airtraffic_all/airtraffic-part/flightmonth=200801\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "airtraffic = spark. \\\n",
    "    read. \\\n",
    "    parquet(airtraffic_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- DayofMonth: integer (nullable = true)\n",
      " |-- DayOfWeek: integer (nullable = true)\n",
      " |-- DepTime: string (nullable = true)\n",
      " |-- CRSDepTime: integer (nullable = true)\n",
      " |-- ArrTime: string (nullable = true)\n",
      " |-- CRSArrTime: integer (nullable = true)\n",
      " |-- UniqueCarrier: string (nullable = true)\n",
      " |-- FlightNum: integer (nullable = true)\n",
      " |-- TailNum: string (nullable = true)\n",
      " |-- ActualElapsedTime: string (nullable = true)\n",
      " |-- CRSElapsedTime: integer (nullable = true)\n",
      " |-- AirTime: string (nullable = true)\n",
      " |-- ArrDelay: string (nullable = true)\n",
      " |-- DepDelay: string (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- Dest: string (nullable = true)\n",
      " |-- Distance: string (nullable = true)\n",
      " |-- TaxiIn: string (nullable = true)\n",
      " |-- TaxiOut: string (nullable = true)\n",
      " |-- Cancelled: integer (nullable = true)\n",
      " |-- CancellationCode: string (nullable = true)\n",
      " |-- Diverted: integer (nullable = true)\n",
      " |-- CarrierDelay: string (nullable = true)\n",
      " |-- WeatherDelay: string (nullable = true)\n",
      " |-- NASDelay: string (nullable = true)\n",
      " |-- SecurityDelay: string (nullable = true)\n",
      " |-- LateAircraftDelay: string (nullable = true)\n",
      " |-- IsArrDelayed: string (nullable = true)\n",
      " |-- IsDepDelayed: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airtraffic.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "605659"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airtraffic.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get number of flights scheduled each day for the month of January 2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat, lpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|FlightDate|count|\n",
      "+----------+-----+\n",
      "|  20080120|18653|\n",
      "|  20080130|19766|\n",
      "|  20080115|19503|\n",
      "|  20080118|20347|\n",
      "|  20080122|19504|\n",
      "|  20080104|20929|\n",
      "|  20080125|20313|\n",
      "|  20080102|20953|\n",
      "|  20080105|18066|\n",
      "|  20080111|20349|\n",
      "|  20080109|19820|\n",
      "|  20080127|18903|\n",
      "|  20080101|19175|\n",
      "|  20080128|20147|\n",
      "|  20080119|16249|\n",
      "|  20080106|19893|\n",
      "|  20080123|19769|\n",
      "|  20080117|20273|\n",
      "|  20080116|19764|\n",
      "|  20080112|16572|\n",
      "|  20080103|20937|\n",
      "|  20080126|16276|\n",
      "|  20080108|19603|\n",
      "|  20080110|20297|\n",
      "|  20080121|20133|\n",
      "|  20080129|19485|\n",
      "|  20080131|20260|\n",
      "|  20080124|20257|\n",
      "|  20080107|20341|\n",
      "|  20080113|18946|\n",
      "|  20080114|20176|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airtraffic. \\\n",
    "    groupBy(concat(\"year\",\n",
    "                   lpad(\"Month\", 2, \"0\"),\n",
    "                   lpad(\"DayOfMonth\", 2, \"0\")\n",
    "                  ).alias(\"FlightDate\")\n",
    "           ). \\\n",
    "    count(). \\\n",
    "    show(31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|FlightDate|FlightCount|\n",
      "+----------+-----------+\n",
      "|  20080120|      18653|\n",
      "|  20080130|      19766|\n",
      "|  20080115|      19503|\n",
      "|  20080118|      20347|\n",
      "|  20080122|      19504|\n",
      "|  20080104|      20929|\n",
      "|  20080125|      20313|\n",
      "|  20080102|      20953|\n",
      "|  20080105|      18066|\n",
      "|  20080111|      20349|\n",
      "|  20080109|      19820|\n",
      "|  20080127|      18903|\n",
      "|  20080101|      19175|\n",
      "|  20080128|      20147|\n",
      "|  20080119|      16249|\n",
      "|  20080106|      19893|\n",
      "|  20080123|      19769|\n",
      "|  20080117|      20273|\n",
      "|  20080116|      19764|\n",
      "|  20080112|      16572|\n",
      "|  20080103|      20937|\n",
      "|  20080126|      16276|\n",
      "|  20080108|      19603|\n",
      "|  20080110|      20297|\n",
      "|  20080121|      20133|\n",
      "|  20080129|      19485|\n",
      "|  20080131|      20260|\n",
      "|  20080124|      20257|\n",
      "|  20080107|      20341|\n",
      "|  20080113|      18946|\n",
      "|  20080114|      20176|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airtraffic. \\\n",
    "    groupBy(concat(\"year\",\n",
    "                   lpad(\"Month\", 2, \"0\"),\n",
    "                   lpad(\"DayOfMonth\", 2, \"0\")\n",
    "                  ).alias(\"FlightDate\")\n",
    "           ). \\\n",
    "    agg(count(lit(1)).alias(\"FlightCount\")). \\\n",
    "    show(31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get count of flights departed, total departure delay and average departure delay for each day over the month of January 2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum, avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-------------+------------------+\n",
      "|FlightDate|FlightCount|TotalDepDelay|   AverageDepDelay|\n",
      "+----------+-----------+-------------+------------------+\n",
      "|  20080120|      18406|     117460.0| 6.381614690861675|\n",
      "|  20080130|      19072|     129345.0| 6.781931627516778|\n",
      "|  20080115|      19204|      75096.0|3.9104353259737556|\n",
      "|  20080118|      20117|     223738.0|11.121837252075359|\n",
      "|  20080122|      18716|     303796.0| 16.23188715537508|\n",
      "|  20080104|      20160|     277373.0|13.758581349206349|\n",
      "|  20080125|      19787|     229850.0|11.616212664880983|\n",
      "|  20080102|      20442|     452979.0|22.159230995010272|\n",
      "|  20080105|      17610|     306068.0|17.380352072685973|\n",
      "|  20080111|      19825|     190918.0|  9.63016393442623|\n",
      "|  20080109|      19443|      89595.0| 4.608085172041352|\n",
      "|  20080127|      18265|     365491.0|20.010457158499865|\n",
      "|  20080101|      18623|     354108.0| 19.01455189819041|\n",
      "|  20080128|      19493|     220046.0|11.288462525008978|\n",
      "|  20080119|      15373|     155488.0|10.114356339035972|\n",
      "|  20080106|      19210|     323214.0| 16.82529932326913|\n",
      "|  20080123|      19239|     190807.0| 9.917719216175477|\n",
      "|  20080117|      19401|     341271.0|17.590381939075307|\n",
      "|  20080116|      19232|      61021.0| 3.172888935108153|\n",
      "|  20080112|      16346|      24876.0|1.5218402055548759|\n",
      "|  20080103|      20462|     329690.0|16.112305737464567|\n",
      "|  20080126|      15860|      92129.0| 5.808890290037831|\n",
      "|  20080108|      19140|     200670.0|10.484326018808778|\n",
      "|  20080110|      19956|     148603.0| 7.446532371216676|\n",
      "|  20080121|      19658|     370196.0| 18.83182419371248|\n",
      "|  20080129|      18596|     184855.0| 9.940578619057861|\n",
      "|  20080131|      19179|     396280.0|20.662182595547215|\n",
      "|  20080124|      19935|     158134.0| 7.932480561825934|\n",
      "|  20080107|      19762|     238431.0|12.065124987349458|\n",
      "|  20080113|      18587|     101753.0| 5.474417603701512|\n",
      "|  20080114|      19267|      98261.0| 5.099963668448643|\n",
      "+----------+-----------+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airtraffic. \\\n",
    "    filter('Cancelled = 0'). \\\n",
    "    groupBy(concat(\"year\",\n",
    "                   lpad(\"Month\", 2, \"0\"),\n",
    "                   lpad(\"DayOfMonth\", 2, \"0\")\n",
    "                  ).alias(\"FlightDate\")\n",
    "           ). \\\n",
    "    agg(\n",
    "        count(lit(1)).alias(\"FlightCount\"),\n",
    "        sum('DepDelay').alias('TotalDepDelay'),\n",
    "        avg('DepDelay').alias('AverageDepDelay')\n",
    "    ). \\\n",
    "    show(31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-------------+---------------+\n",
      "|FlightDate|FlightCount|TotalDepDelay|AverageDepDelay|\n",
      "+----------+-----------+-------------+---------------+\n",
      "|  20080120|      18406|     117460.0|           6.38|\n",
      "|  20080130|      19072|     129345.0|           6.78|\n",
      "|  20080115|      19204|      75096.0|           3.91|\n",
      "|  20080118|      20117|     223738.0|          11.12|\n",
      "|  20080122|      18716|     303796.0|          16.23|\n",
      "|  20080104|      20160|     277373.0|          13.76|\n",
      "|  20080125|      19787|     229850.0|          11.62|\n",
      "|  20080102|      20442|     452979.0|          22.16|\n",
      "|  20080105|      17610|     306068.0|          17.38|\n",
      "|  20080111|      19825|     190918.0|           9.63|\n",
      "|  20080109|      19443|      89595.0|           4.61|\n",
      "|  20080127|      18265|     365491.0|          20.01|\n",
      "|  20080101|      18623|     354108.0|          19.01|\n",
      "|  20080128|      19493|     220046.0|          11.29|\n",
      "|  20080119|      15373|     155488.0|          10.11|\n",
      "|  20080106|      19210|     323214.0|          16.83|\n",
      "|  20080123|      19239|     190807.0|           9.92|\n",
      "|  20080117|      19401|     341271.0|          17.59|\n",
      "|  20080116|      19232|      61021.0|           3.17|\n",
      "|  20080112|      16346|      24876.0|           1.52|\n",
      "|  20080103|      20462|     329690.0|          16.11|\n",
      "|  20080126|      15860|      92129.0|           5.81|\n",
      "|  20080108|      19140|     200670.0|          10.48|\n",
      "|  20080110|      19956|     148603.0|           7.45|\n",
      "|  20080121|      19658|     370196.0|          18.83|\n",
      "|  20080129|      18596|     184855.0|           9.94|\n",
      "|  20080131|      19179|     396280.0|          20.66|\n",
      "|  20080124|      19935|     158134.0|           7.93|\n",
      "|  20080107|      19762|     238431.0|          12.07|\n",
      "|  20080113|      18587|     101753.0|           5.47|\n",
      "|  20080114|      19267|      98261.0|            5.1|\n",
      "+----------+-----------+-------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airtraffic. \\\n",
    "    filter('Cancelled = 0'). \\\n",
    "    groupBy(concat(\"year\",\n",
    "                   lpad(\"Month\", 2, \"0\"),\n",
    "                   lpad(\"DayOfMonth\", 2, \"0\")\n",
    "                  ).alias(\"FlightDate\")\n",
    "           ). \\\n",
    "    agg(\n",
    "        count(lit(1)).alias(\"FlightCount\"),\n",
    "        sum('DepDelay').alias('TotalDepDelay'),\n",
    "        round(avg('DepDelay'), 2).alias('AverageDepDelay')\n",
    "    ). \\\n",
    "    show(31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using order_items, get revenue for each order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_items_path = '/public/retail_db_json/order_items'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_items = spark. \\\n",
    "    read. \\\n",
    "    json(order_items_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_item_id: long (nullable = true)\n",
      " |-- order_item_order_id: long (nullable = true)\n",
      " |-- order_item_product_id: long (nullable = true)\n",
      " |-- order_item_product_price: double (nullable = true)\n",
      " |-- order_item_quantity: long (nullable = true)\n",
      " |-- order_item_subtotal: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_items.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------------+\n",
      "|order_item_order_id|sum(order_item_subtotal)|\n",
      "+-------------------+------------------------+\n",
      "|                 29|                 1109.85|\n",
      "|                474|       774.8199999999999|\n",
      "|                964|       739.8800000000001|\n",
      "|               1677|       649.9200000000001|\n",
      "|               1806|                  789.94|\n",
      "|               1950|      1015.8700000000001|\n",
      "|               2214|                  449.96|\n",
      "|               2250|                  889.94|\n",
      "|               2453|       999.9300000000001|\n",
      "|               2509|                  889.94|\n",
      "|               2529|                   59.99|\n",
      "|               2927|       999.9100000000001|\n",
      "|               3091|      469.93000000000006|\n",
      "|               3764|                   95.98|\n",
      "|               4590|                  949.83|\n",
      "|               4894|                  899.94|\n",
      "|               5385|                  629.86|\n",
      "|               5409|       699.9200000000001|\n",
      "|               6721|                  139.99|\n",
      "|               7225|                  774.86|\n",
      "+-------------------+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_items. \\\n",
    "    groupBy('order_item_order_id'). \\\n",
    "    sum('order_item_subtotal'). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+\n",
      "|order_item_order_id| revenue_per_order|\n",
      "+-------------------+------------------+\n",
      "|                 29|           1109.85|\n",
      "|                474| 774.8199999999999|\n",
      "|                964| 739.8800000000001|\n",
      "|               1677| 649.9200000000001|\n",
      "|               1806|            789.94|\n",
      "|               1950|1015.8700000000001|\n",
      "|               2214|            449.96|\n",
      "|               2250|            889.94|\n",
      "|               2453| 999.9300000000001|\n",
      "|               2509|            889.94|\n",
      "|               2529|             59.99|\n",
      "|               2927| 999.9100000000001|\n",
      "|               3091|469.93000000000006|\n",
      "|               3764|             95.98|\n",
      "|               4590|            949.83|\n",
      "|               4894|            899.94|\n",
      "|               5385|            629.86|\n",
      "|               5409| 699.9200000000001|\n",
      "|               6721|            139.99|\n",
      "|               7225|            774.86|\n",
      "+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_items. \\\n",
    "    groupBy('order_item_order_id'). \\\n",
    "    agg(sum('order_item_subtotal').alias('revenue_per_order')). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------+\n",
      "|order_item_order_id|revenue_per_order|\n",
      "+-------------------+-----------------+\n",
      "|                 29|          1109.85|\n",
      "|                474|           774.82|\n",
      "|                964|           739.88|\n",
      "|               1677|           649.92|\n",
      "|               1806|           789.94|\n",
      "|               1950|          1015.87|\n",
      "|               2214|           449.96|\n",
      "|               2250|           889.94|\n",
      "|               2453|           999.93|\n",
      "|               2509|           889.94|\n",
      "|               2529|            59.99|\n",
      "|               2927|           999.91|\n",
      "|               3091|           469.93|\n",
      "|               3764|            95.98|\n",
      "|               4590|           949.83|\n",
      "|               4894|           899.94|\n",
      "|               5385|           629.86|\n",
      "|               5409|           699.92|\n",
      "|               6721|           139.99|\n",
      "|               7225|           774.86|\n",
      "+-------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_items. \\\n",
    "    groupBy('order_item_order_id'). \\\n",
    "    agg(round(sum('order_item_subtotal'), 2).alias('revenue_per_order')). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get min and max order_item_subtotal for each order id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import min, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------+-----------------------+-----------------------+\n",
      "|order_item_order_id|revenue_per_order|order_item_subtotal_min|order_item_subtotal_max|\n",
      "+-------------------+-----------------+-----------------------+-----------------------+\n",
      "|              39713|           599.97|                 199.99|                 399.98|\n",
      "|              40395|           939.94|                   50.0|                 399.98|\n",
      "|              40436|           229.98|                  99.99|                 129.99|\n",
      "|              40557|           549.95|                   50.0|                  200.0|\n",
      "|              40634|          1119.88|                  99.99|                 499.95|\n",
      "|              41424|           829.95|                 129.99|                 299.98|\n",
      "|              41895|            649.9|                   50.0|                 199.99|\n",
      "|              41988|            669.9|                 129.99|                 299.95|\n",
      "|              42126|           899.88|                  249.9|                 399.98|\n",
      "|              42852|          1039.88|                 129.99|                 399.98|\n",
      "|              42969|           561.96|                  31.99|                 399.98|\n",
      "|              43367|          1079.87|                 129.99|                 399.98|\n",
      "|              44134|           759.92|                 119.98|                 399.98|\n",
      "|              44342|           119.98|                 119.98|                 119.98|\n",
      "|              44901|          1129.87|                 129.99|                 399.98|\n",
      "|              45166|           424.92|                   50.0|                 129.99|\n",
      "|              45298|           759.93|                  79.98|                 199.99|\n",
      "|              45726|          1149.88|                 119.97|                 399.98|\n",
      "|              46044|           1159.9|                  39.98|                 399.98|\n",
      "|              46424|           509.84|                 109.94|                 149.94|\n",
      "+-------------------+-----------------+-----------------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_items. \\\n",
    "    groupBy('order_item_order_id'). \\\n",
    "    agg(\n",
    "        round(sum('order_item_subtotal'), 2).alias('revenue_per_order'),\n",
    "        min('order_item_subtotal').alias('order_item_subtotal_min'),\n",
    "        max('order_item_subtotal').alias('order_item_subtotal_max')\n",
    "    ). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
