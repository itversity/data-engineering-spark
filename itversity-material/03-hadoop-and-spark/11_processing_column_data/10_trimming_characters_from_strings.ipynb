{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trimming Characters from Strings\n",
    "Let us go through how to trim unwanted characters using Spark Functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/qWv8zfSOPZM?rel=0&amp;controls=1&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/qWv8zfSOPZM?rel=0&amp;controls=1&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We typically use trimming to remove unnecessary characters from fixed length records.\n",
    "* Fixed length records are extensively used in Mainframes and we might have to process it using Spark.\n",
    "* As part of processing we might want to remove leading or trailing characters such as 0 in case of numeric types and space or some standard character in case of alphanumeric types.\n",
    "* As of now Spark trim functions take the column as argument and remove leading or trailing spaces. However, we can use `expr` or `selectExpr` to use Spark SQL based trim functions to remove leading or trailing spaces or any other such characters.\n",
    "  * Trim spaces towards left - `ltrim`\n",
    "  * Trim spaces towards right - `rtrim`\n",
    "  * Trim spaces on both sides - `trim`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start spark context for this Notebook so that we can execute the code provided. You can sign up for our [10 node state of the art cluster/labs](https://labs.itversity.com/plans) to learn Spark SQL using our unique integrated LMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    config('spark.ui.port', '0'). \\\n",
    "    config(\"spark.sql.warehouse.dir\", f\"/user/{username}/warehouse\"). \\\n",
    "    enableHiveSupport(). \\\n",
    "    appName(f'{username} | Python - Processing Column Data'). \\\n",
    "    master('yarn'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are going to use CLIs, you can use Spark SQL using one of the 3 approaches.\n",
    "\n",
    "**Using Spark SQL**\n",
    "\n",
    "```\n",
    "spark2-sql \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```\n",
    "\n",
    "**Using Scala**\n",
    "\n",
    "```\n",
    "spark2-shell \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```\n",
    "\n",
    "**Using Pyspark**\n",
    "\n",
    "```\n",
    "pyspark2 \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks - Trimming Strings\n",
    "\n",
    "Let us understand how to use trim functions to remove spaces on left or right or both.\n",
    "* Create a Dataframe with one column and one record.\n",
    "* Apply trim functions to trim spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "l = [(\"   Hello.    \",) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(l).toDF(\"dummy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|        dummy|\n",
      "+-------------+\n",
      "|   Hello.    |\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, ltrim, rtrim, trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+---------+------+\n",
      "|        dummy|     ltrim|    rtrim|  trim|\n",
      "+-------------+----------+---------+------+\n",
      "|   Hello.    |Hello.    |   Hello.|Hello.|\n",
      "+-------------+----------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"ltrim\", ltrim(col(\"dummy\"))). \\\n",
    "  withColumn(\"rtrim\", rtrim(col(\"dummy\"))). \\\n",
    "  withColumn(\"trim\", trim(col(\"dummy\"))). \\\n",
    "  show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|function_desc                                                                                                                                                                                         |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Function: rtrim                                                                                                                                                                                       |\n",
      "|Class: org.apache.spark.sql.catalyst.expressions.StringTrimRight                                                                                                                                      |\n",
      "|Usage: \n",
      "    rtrim(str) - Removes the trailing space characters from `str`.\n",
      "\n",
      "    rtrim(trimStr, str) - Removes the trailing string which contains the characters from the trim string from the `str`\n",
      "  |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('DESCRIBE FUNCTION rtrim').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+--------+------+\n",
      "|        dummy|     ltrim|   rtrim|  trim|\n",
      "+-------------+----------+--------+------+\n",
      "|   Hello.    |Hello.    |   Hello|Hello.|\n",
      "+-------------+----------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# if we do not specify trimStr, it will be defaulted to space\n",
    "df.withColumn(\"ltrim\", expr(\"ltrim(dummy)\")). \\\n",
    "  withColumn(\"rtrim\", expr(\"rtrim('.', rtrim(dummy))\")). \\\n",
    "  withColumn(\"trim\", trim(col(\"dummy\"))). \\\n",
    "  show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|function_desc                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Function: trim                                                                                                                                                                                                                                                                                                                                                                 |\n",
      "|Class: org.apache.spark.sql.catalyst.expressions.StringTrim                                                                                                                                                                                                                                                                                                                    |\n",
      "|Usage: \n",
      "    trim(str) - Removes the leading and trailing space characters from `str`.\n",
      "\n",
      "    trim(BOTH trimStr FROM str) - Remove the leading and trailing `trimStr` characters from `str`\n",
      "\n",
      "    trim(LEADING trimStr FROM str) - Remove the leading `trimStr` characters from `str`\n",
      "\n",
      "    trim(TRAILING trimStr FROM str) - Remove the trailing `trimStr` characters from `str`\n",
      "  |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('DESCRIBE FUNCTION trim').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+--------+------+\n",
      "|        dummy|     ltrim|   rtrim|  trim|\n",
      "+-------------+----------+--------+------+\n",
      "|   Hello.    |Hello.    |   Hello|Hello.|\n",
      "+-------------+----------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"ltrim\", expr(\"trim(LEADING ' ' FROM dummy)\")). \\\n",
    "  withColumn(\"rtrim\", expr(\"trim(TRAILING '.' FROM rtrim(dummy))\")). \\\n",
    "  withColumn(\"trim\", expr(\"trim(BOTH ' ' FROM dummy)\")). \\\n",
    "  show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 2",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
