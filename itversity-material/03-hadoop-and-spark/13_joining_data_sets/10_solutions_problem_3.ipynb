{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions - Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/G3qhRq3wows?rel=0&amp;controls=1&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/G3qhRq3wows?rel=0&amp;controls=1&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the list of airports in the US from which flights are not departed in the month of 2008 January.\n",
    "\n",
    "* This is an example for outer join.\n",
    "* We need to get those airports which are in airport codes but not in 2008 January airtraffic data set.\n",
    "* Based on the side of the airport codes data set, we can say left or right. We will invoke join using airport codes data set and hence we will use left outer join."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start spark context for this Notebook so that we can execute the code provided. You can sign up for our [10 node state of the art cluster/labs](https://labs.itversity.com/plans) to learn Spark SQL using our unique integrated LMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    config('spark.ui.port', '0'). \\\n",
    "    config(\"spark.sql.warehouse.dir\", f\"/user/{username}/warehouse\"). \\\n",
    "    enableHiveSupport(). \\\n",
    "    appName(f'{username} | Python - Joining Data Sets'). \\\n",
    "    master('yarn'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are going to use CLIs, you can use Spark SQL using one of the 3 approaches.\n",
    "\n",
    "**Using Spark SQL**\n",
    "\n",
    "```\n",
    "spark2-sql \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```\n",
    "\n",
    "**Using Scala**\n",
    "\n",
    "```\n",
    "spark2-shell \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```\n",
    "\n",
    "**Using Pyspark**\n",
    "\n",
    "```\n",
    "pyspark2 \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "airtrafficPath = \"/public/airtraffic_all/airtraffic-part/flightmonth=200801\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "airtraffic = spark. \\\n",
    "    read. \\\n",
    "    parquet(airtrafficPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+------+----+----------+\n",
      "|Year|Month|DayOfMonth|Origin|Dest|CRSDepTime|\n",
      "+----+-----+----------+------+----+----------+\n",
      "|2008|    1|        16|   BGR| CVG|      1735|\n",
      "|2008|    1|        17|   SYR| CVG|      1701|\n",
      "|2008|    1|        17|   SAV| BOS|      1225|\n",
      "|2008|    1|        17|   CVG| GRR|      1530|\n",
      "|2008|    1|        17|   STL| CVG|      1205|\n",
      "|2008|    1|        18|   STL| JFK|      1150|\n",
      "|2008|    1|        18|   MCI| CVG|      1009|\n",
      "|2008|    1|        19|   TUL| CVG|       835|\n",
      "|2008|    1|        20|   JFK| PHL|      1935|\n",
      "|2008|    1|        20|   RDU| CVG|       830|\n",
      "|2008|    1|        21|   CVG| DTW|      1640|\n",
      "|2008|    1|        21|   MSY| LGA|      1204|\n",
      "|2008|    1|        21|   JFK| PHL|      1935|\n",
      "|2008|    1|        21|   DCA| JFK|      1830|\n",
      "|2008|    1|        21|   HSV| DCA|       700|\n",
      "|2008|    1|        22|   ORD| CVG|      1910|\n",
      "|2008|    1|        22|   CVG| JFK|      1320|\n",
      "|2008|    1|        23|   LGA| SAV|       908|\n",
      "|2008|    1|        23|   CLT| CVG|      1252|\n",
      "|2008|    1|        23|   GSP| LGA|       635|\n",
      "+----+-----+----------+------+----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airtraffic. \\\n",
    "    select(\n",
    "        \"Year\", \"Month\", \"DayOfMonth\", \n",
    "        \"Origin\", \"Dest\", \"CRSDepTime\"\n",
    "    ). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "605659"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airtraffic.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "airportCodesPath = \"/public/airtraffic_all/airport-codes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValidAirportCodes(airportCodesPath):\n",
    "    airportCodes = spark. \\\n",
    "        read. \\\n",
    "        option(\"sep\", \"\\t\"). \\\n",
    "        option(\"header\", True). \\\n",
    "        option(\"inferSchema\", True). \\\n",
    "        csv(airportCodesPath). \\\n",
    "        filter(\"!(State = 'Hawaii' AND IATA = 'Big') AND Country = 'USA'\")\n",
    "    return airportCodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "airportCodes = getValidAirportCodes(airportCodesPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "443"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airportCodes.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+-------+----+------+\n",
      "|          City|State|Country|IATA|Origin|\n",
      "+--------------+-----+-------+----+------+\n",
      "|      Aberdeen|   SD|    USA| ABR|  null|\n",
      "|       Alamosa|   CO|    USA| ALS|  null|\n",
      "|      Alliance|   NE|    USA| AIA|  null|\n",
      "|        Alpena|   MI|    USA| APN|  null|\n",
      "|       Altoona|   PA|    USA| AOO|  null|\n",
      "|        Athens|   GA|    USA| AHN|  null|\n",
      "|       Augusta|   ME|    USA| AUG|  null|\n",
      "|    Bar Harbor|   ME|    USA| BHB|  null|\n",
      "|       Beckley|   WV|    USA| BKW|  null|\n",
      "|       Bedford|   MA|    USA| BED|  null|\n",
      "|       Bemidji|   MN|    USA| BJI|  null|\n",
      "|       Bettles|   AK|    USA| BTT|  null|\n",
      "|   Bloomington|   IN|    USA| BMG|  null|\n",
      "|     Bluefield|   WV|    USA| BLF|  null|\n",
      "|     Brookings|   SD|    USA| BKX|  null|\n",
      "|    Burlington|   IA|    USA| BRL|  null|\n",
      "|    Burlington|   MA|    USA| BBF|  null|\n",
      "|Cape Girardeau|   MO|    USA| CGI|  null|\n",
      "|      Carlsbad|   NM|    USA| CNM|  null|\n",
      "|      Cheyenne|   WY|    USA| CYS|  null|\n",
      "+--------------+-----+-------+----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airportCodes. \\\n",
    "    join(airtraffic, col(\"IATA\") == col(\"Origin\"), \"left\"). \\\n",
    "    filter(\"Origin IS NULL\"). \\\n",
    "    select(airportCodes[\"*\"], col(\"Origin\")). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airportCodes. \\\n",
    "    join(airtraffic, col(\"IATA\") == col(\"Origin\"), \"left\"). \\\n",
    "    filter(\"Origin IS NULL\"). \\\n",
    "    count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 2",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
