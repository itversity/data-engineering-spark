{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering example using dates\n",
    "\n",
    "Let us understand how to filter the data using dates leveraging appropriate date manipulation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/LT9MhsT9qFA?rel=0&amp;controls=1&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/LT9MhsT9qFA?rel=0&amp;controls=1&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start spark context for this Notebook so that we can execute the code provided. You can sign up for our [10 node state of the art cluster/labs](https://labs.itversity.com/plans) to learn Spark SQL using our unique integrated LMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    config('spark.ui.port', '0'). \\\n",
    "    config(\"spark.sql.warehouse.dir\", f\"/user/{username}/warehouse\"). \\\n",
    "    enableHiveSupport(). \\\n",
    "    appName(f'{username} | Python - Basic Transformations'). \\\n",
    "    master('yarn'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are going to use CLIs, you can use Spark SQL using one of the 3 approaches.\n",
    "\n",
    "**Using Spark SQL**\n",
    "\n",
    "```\n",
    "spark2-sql \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```\n",
    "\n",
    "**Using Scala**\n",
    "\n",
    "```\n",
    "spark2-shell \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```\n",
    "\n",
    "**Using Pyspark**\n",
    "\n",
    "```\n",
    "pyspark2 \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "Let us perform some tasks to understand filtering in detail. Solve all the problems by passing  conditions using both SQL Style as well as API Style.\n",
    "\n",
    "* Read the data for the month of 2008 January. We will be using only 2008 January data for the demos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "airtraffic_path = \"/public/airtraffic_all/airtraffic-part/flightmonth=200801\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "airtraffic = spark. \\\n",
    "    read. \\\n",
    "    parquet(airtraffic_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- DayofMonth: integer (nullable = true)\n",
      " |-- DayOfWeek: integer (nullable = true)\n",
      " |-- DepTime: string (nullable = true)\n",
      " |-- CRSDepTime: integer (nullable = true)\n",
      " |-- ArrTime: string (nullable = true)\n",
      " |-- CRSArrTime: integer (nullable = true)\n",
      " |-- UniqueCarrier: string (nullable = true)\n",
      " |-- FlightNum: integer (nullable = true)\n",
      " |-- TailNum: string (nullable = true)\n",
      " |-- ActualElapsedTime: string (nullable = true)\n",
      " |-- CRSElapsedTime: integer (nullable = true)\n",
      " |-- AirTime: string (nullable = true)\n",
      " |-- ArrDelay: string (nullable = true)\n",
      " |-- DepDelay: string (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- Dest: string (nullable = true)\n",
      " |-- Distance: string (nullable = true)\n",
      " |-- TaxiIn: string (nullable = true)\n",
      " |-- TaxiOut: string (nullable = true)\n",
      " |-- Cancelled: integer (nullable = true)\n",
      " |-- CancellationCode: string (nullable = true)\n",
      " |-- Diverted: integer (nullable = true)\n",
      " |-- CarrierDelay: string (nullable = true)\n",
      " |-- WeatherDelay: string (nullable = true)\n",
      " |-- NASDelay: string (nullable = true)\n",
      " |-- SecurityDelay: string (nullable = true)\n",
      " |-- LateAircraftDelay: string (nullable = true)\n",
      " |-- IsArrDelayed: string (nullable = true)\n",
      " |-- IsDepDelayed: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airtraffic.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+\n",
      "|Year|Month|DayOfMonth|\n",
      "+----+-----+----------+\n",
      "|2008|    1|        28|\n",
      "|2008|    1|        25|\n",
      "|2008|    1|        20|\n",
      "|2008|    1|        11|\n",
      "|2008|    1|         4|\n",
      "|2008|    1|         5|\n",
      "|2008|    1|        15|\n",
      "|2008|    1|         3|\n",
      "|2008|    1|        16|\n",
      "|2008|    1|         9|\n",
      "|2008|    1|        17|\n",
      "|2008|    1|        19|\n",
      "|2008|    1|        12|\n",
      "|2008|    1|         6|\n",
      "|2008|    1|        21|\n",
      "|2008|    1|        18|\n",
      "|2008|    1|         7|\n",
      "|2008|    1|         1|\n",
      "|2008|    1|        26|\n",
      "|2008|    1|        24|\n",
      "|2008|    1|        23|\n",
      "|2008|    1|         8|\n",
      "|2008|    1|         2|\n",
      "|2008|    1|        14|\n",
      "|2008|    1|        10|\n",
      "|2008|    1|        13|\n",
      "|2008|    1|        27|\n",
      "|2008|    1|        29|\n",
      "|2008|    1|        30|\n",
      "|2008|    1|        22|\n",
      "|2008|    1|        31|\n",
      "+----+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airtraffic.select('Year', 'Month', 'DayOfMonth').distinct().show(31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airtraffic.select('Year', 'Month', 'DayOfMonth').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "605659"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airtraffic.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get number of flights departed late on Sundays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [('X',)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(l, \"dummy STRING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|dummy|\n",
      "+-----+\n",
      "|    X|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|current_date()|\n",
      "+--------------+\n",
      "|    2021-03-01|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(current_date()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import date_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|current_date|day_name|\n",
      "+------------+--------+\n",
      "|  2021-03-01|     Mon|\n",
      "+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(current_date().alias('current_date'), date_format(current_date(), 'EE').alias('day_name')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|current_date|day_name|\n",
      "+------------+--------+\n",
      "|  2021-03-01|  Monday|\n",
      "+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(current_date().alias('current_date'), date_format(current_date(), 'EEEE').alias('day_name')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+\n",
      "|Year|Month|DayOfMonth|\n",
      "+----+-----+----------+\n",
      "|2008|    1|        16|\n",
      "|2008|    1|        17|\n",
      "|2008|    1|        17|\n",
      "|2008|    1|        17|\n",
      "|2008|    1|        17|\n",
      "|2008|    1|        18|\n",
      "|2008|    1|        18|\n",
      "|2008|    1|        19|\n",
      "|2008|    1|        20|\n",
      "|2008|    1|        20|\n",
      "|2008|    1|        21|\n",
      "|2008|    1|        21|\n",
      "|2008|    1|        21|\n",
      "|2008|    1|        21|\n",
      "|2008|    1|        21|\n",
      "|2008|    1|        22|\n",
      "|2008|    1|        22|\n",
      "|2008|    1|        23|\n",
      "|2008|    1|        23|\n",
      "|2008|    1|        23|\n",
      "+----+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airtraffic.select('Year', 'Month', 'DayOfMonth').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lpad, concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|FlightDate|\n",
      "+----------+\n",
      "|  20080116|\n",
      "|  20080117|\n",
      "|  20080117|\n",
      "|  20080117|\n",
      "|  20080117|\n",
      "|  20080118|\n",
      "|  20080118|\n",
      "|  20080119|\n",
      "|  20080120|\n",
      "|  20080120|\n",
      "|  20080121|\n",
      "|  20080121|\n",
      "|  20080121|\n",
      "|  20080121|\n",
      "|  20080121|\n",
      "|  20080122|\n",
      "|  20080122|\n",
      "|  20080123|\n",
      "|  20080123|\n",
      "|  20080123|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airtraffic.select(\n",
    "    concat(\n",
    "        col(\"Year\"),\n",
    "        lpad(col(\"Month\"), 2, \"0\"),\n",
    "        lpad(col(\"DayOfMonth\"), 2, \"0\")\n",
    "    ).alias('FlightDate')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|FlightDate|\n",
      "+----------+\n",
      "|2008-01-16|\n",
      "|2008-01-17|\n",
      "|2008-01-17|\n",
      "|2008-01-17|\n",
      "|2008-01-17|\n",
      "|2008-01-18|\n",
      "|2008-01-18|\n",
      "|2008-01-19|\n",
      "|2008-01-20|\n",
      "|2008-01-20|\n",
      "|2008-01-21|\n",
      "|2008-01-21|\n",
      "|2008-01-21|\n",
      "|2008-01-21|\n",
      "|2008-01-21|\n",
      "|2008-01-22|\n",
      "|2008-01-22|\n",
      "|2008-01-23|\n",
      "|2008-01-23|\n",
      "|2008-01-23|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airtraffic. \\\n",
    "    select(\n",
    "        concat(\n",
    "            col(\"Year\"),\n",
    "            lpad(col(\"Month\"), 2, \"0\"),\n",
    "            lpad(col(\"DayOfMonth\"), 2, \"0\")\n",
    "        ).alias('FlightDate')\n",
    "    ). \\\n",
    "    selectExpr(\"to_date(FlightDate, 'yyyyMMdd') AS FlightDate\"). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|FlightDay|\n",
      "+---------+\n",
      "|Wednesday|\n",
      "| Thursday|\n",
      "| Thursday|\n",
      "| Thursday|\n",
      "| Thursday|\n",
      "|   Friday|\n",
      "|   Friday|\n",
      "| Saturday|\n",
      "|   Sunday|\n",
      "|   Sunday|\n",
      "|   Monday|\n",
      "|   Monday|\n",
      "|   Monday|\n",
      "|   Monday|\n",
      "|   Monday|\n",
      "|  Tuesday|\n",
      "|  Tuesday|\n",
      "|Wednesday|\n",
      "|Wednesday|\n",
      "|Wednesday|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airtraffic. \\\n",
    "    select(\n",
    "        concat(\n",
    "            col(\"Year\"),\n",
    "            lpad(col(\"Month\"), 2, \"0\"),\n",
    "            lpad(col(\"DayOfMonth\"), 2, \"0\")\n",
    "        ).alias('FlightDate')\n",
    "    ). \\\n",
    "    selectExpr(\"date_format(to_date(FlightDate, 'yyyyMMdd'), 'EEEE') AS FlightDay\"). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import date_format, to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|FlightDay|\n",
      "+---------+\n",
      "|Wednesday|\n",
      "| Thursday|\n",
      "| Thursday|\n",
      "| Thursday|\n",
      "| Thursday|\n",
      "|   Friday|\n",
      "|   Friday|\n",
      "| Saturday|\n",
      "|   Sunday|\n",
      "|   Sunday|\n",
      "|   Monday|\n",
      "|   Monday|\n",
      "|   Monday|\n",
      "|   Monday|\n",
      "|   Monday|\n",
      "|  Tuesday|\n",
      "|  Tuesday|\n",
      "|Wednesday|\n",
      "|Wednesday|\n",
      "|Wednesday|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airtraffic. \\\n",
    "    select(\n",
    "        concat(\n",
    "            col(\"Year\"),\n",
    "            lpad(col(\"Month\"), 2, \"0\"),\n",
    "            lpad(col(\"DayOfMonth\"), 2, \"0\")\n",
    "        ).alias('FlightDate')\n",
    "    ). \\\n",
    "    select(date_format(to_date('FlightDate', 'yyyyMMdd'), 'EEEE').alias('FlightDay')). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, concat, lpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76395"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airtraffic. \\\n",
    "    withColumn(\"FlightDate\",\n",
    "               concat(col(\"Year\"),\n",
    "                      lpad(col(\"Month\"), 2, \"0\"),\n",
    "                      lpad(col(\"DayOfMonth\"), 2, \"0\")\n",
    "                     )\n",
    "              ). \\\n",
    "    filter(\"\"\"\n",
    "           date_format(to_date(FlightDate, 'yyyyMMdd'), 'EEEE') = 'Sunday'\n",
    "           \"\"\"). \\\n",
    "    count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34708"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airtraffic. \\\n",
    "    withColumn(\"FlightDate\",\n",
    "               concat(col(\"Year\"),\n",
    "                      lpad(col(\"Month\"), 2, \"0\"),\n",
    "                      lpad(col(\"DayOfMonth\"), 2, \"0\")\n",
    "                     )\n",
    "              ). \\\n",
    "    filter(\"\"\"\n",
    "           IsDepDelayed = 'YES' AND \n",
    "           date_format(to_date(FlightDate, 'yyyyMMdd'), 'EEEE') = 'Sunday'\n",
    "           \"\"\"). \\\n",
    "    count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* API Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, concat, lpad, \\\n",
    "    date_format, to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34708"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airtraffic. \\\n",
    "    withColumn(\"FlightDate\",\n",
    "               concat(col(\"Year\"),\n",
    "                      lpad(col(\"Month\"), 2, \"0\"),\n",
    "                      lpad(col(\"DayOfMonth\"), 2, \"0\")\n",
    "                     )\n",
    "              ). \\\n",
    "    filter((col(\"IsDepDelayed\") == \"YES\") &\n",
    "           (date_format(\n",
    "               to_date(\"FlightDate\", \"yyyyMMdd\"), \"EEEE\"\n",
    "           ) == \"Sunday\")\n",
    "          ). \\\n",
    "    count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 2",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
