{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Solutions - Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/jk50Dh-i08w?rel=0&amp;controls=1&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/jk50Dh-i08w?rel=0&amp;controls=1&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Get number of flights which are delayed in departure and number of flights delayed in arrival for each day along with number of flights departed for each day. \n",
    "\n",
    "* Output should contain 4 columns - **FlightDate**, **FlightCount**, **DepDelayedCount**, **ArrDelayedCount**\n",
    "* **FlightDate** should be of **yyyy-MM-dd** format.\n",
    "*   Data should be **sorted** in ascending order by **flightDate**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start spark context for this Notebook so that we can execute the code provided. You can sign up for our [10 node state of the art cluster/labs](https://labs.itversity.com/plans) to learn Spark SQL using our unique integrated LMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    config('spark.ui.port', '0'). \\\n",
    "    config(\"spark.sql.warehouse.dir\", f\"/user/{username}/warehouse\"). \\\n",
    "    enableHiveSupport(). \\\n",
    "    appName(f'{username} | Python - Basic Transformations'). \\\n",
    "    master('yarn'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are going to use CLIs, you can use Spark SQL using one of the 3 approaches.\n",
    "\n",
    "**Using Spark SQL**\n",
    "\n",
    "```\n",
    "spark2-sql \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```\n",
    "\n",
    "**Using Scala**\n",
    "\n",
    "```\n",
    "spark2-shell \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```\n",
    "\n",
    "**Using Pyspark**\n",
    "\n",
    "```\n",
    "pyspark2 \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading airtraffic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "airtraffic_path = \"/public/airtraffic_all/airtraffic-part/flightmonth=200801\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "airtraffic = spark. \\\n",
    "    read. \\\n",
    "    parquet(airtraffic_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- DayofMonth: integer (nullable = true)\n",
      " |-- DayOfWeek: integer (nullable = true)\n",
      " |-- DepTime: string (nullable = true)\n",
      " |-- CRSDepTime: integer (nullable = true)\n",
      " |-- ArrTime: string (nullable = true)\n",
      " |-- CRSArrTime: integer (nullable = true)\n",
      " |-- UniqueCarrier: string (nullable = true)\n",
      " |-- FlightNum: integer (nullable = true)\n",
      " |-- TailNum: string (nullable = true)\n",
      " |-- ActualElapsedTime: string (nullable = true)\n",
      " |-- CRSElapsedTime: integer (nullable = true)\n",
      " |-- AirTime: string (nullable = true)\n",
      " |-- ArrDelay: string (nullable = true)\n",
      " |-- DepDelay: string (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- Dest: string (nullable = true)\n",
      " |-- Distance: string (nullable = true)\n",
      " |-- TaxiIn: string (nullable = true)\n",
      " |-- TaxiOut: string (nullable = true)\n",
      " |-- Cancelled: integer (nullable = true)\n",
      " |-- CancellationCode: string (nullable = true)\n",
      " |-- Diverted: integer (nullable = true)\n",
      " |-- CarrierDelay: string (nullable = true)\n",
      " |-- WeatherDelay: string (nullable = true)\n",
      " |-- NASDelay: string (nullable = true)\n",
      " |-- SecurityDelay: string (nullable = true)\n",
      " |-- LateAircraftDelay: string (nullable = true)\n",
      " |-- IsArrDelayed: string (nullable = true)\n",
      " |-- IsDepDelayed: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airtraffic.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Grouping Data by Flight Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, concat, lpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.group.GroupedData at 0x7fc369243940>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airtraffic. \\\n",
    "  groupBy(concat(\"Year\", lit(\"-\"), \n",
    "                 lpad(\"Month\", 2, \"0\"), lit(\"-\"), \n",
    "                 lpad(\"DayOfMonth\", 2, \"0\")).\n",
    "          alias(\"FlightDate\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Counts by FlightDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|FlightDate|FlightCount|\n",
      "+----------+-----------+\n",
      "|2008-01-15|      19204|\n",
      "|2008-01-21|      19658|\n",
      "|2008-01-11|      19825|\n",
      "|2008-01-19|      15373|\n",
      "|2008-01-02|      20442|\n",
      "|2008-01-06|      19210|\n",
      "|2008-01-29|      18596|\n",
      "|2008-01-30|      19072|\n",
      "|2008-01-17|      19401|\n",
      "|2008-01-31|      19179|\n",
      "|2008-01-01|      18623|\n",
      "|2008-01-24|      19935|\n",
      "|2008-01-07|      19762|\n",
      "|2008-01-09|      19443|\n",
      "|2008-01-04|      20160|\n",
      "|2008-01-08|      19140|\n",
      "|2008-01-05|      17610|\n",
      "|2008-01-25|      19787|\n",
      "|2008-01-26|      15860|\n",
      "|2008-01-12|      16346|\n",
      "|2008-01-16|      19232|\n",
      "|2008-01-23|      19239|\n",
      "|2008-01-18|      20117|\n",
      "|2008-01-22|      18716|\n",
      "|2008-01-28|      19493|\n",
      "|2008-01-13|      18587|\n",
      "|2008-01-10|      19956|\n",
      "|2008-01-14|      19267|\n",
      "|2008-01-20|      18406|\n",
      "|2008-01-27|      18265|\n",
      "|2008-01-03|      20462|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airtraffic. \\\n",
    "    filter('Cancelled = 0'). \\\n",
    "    groupBy(concat(\"Year\", lit(\"-\"), \n",
    "                   lpad(\"Month\", 2, \"0\"), lit(\"-\"), \n",
    "                   lpad(\"DayOfMonth\", 2, \"0\")).\n",
    "            alias(\"FlightDate\")). \\\n",
    "    agg(count(lit(1)).alias(\"FlightCount\")). \\\n",
    "    show(31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative to get the count with out using agg\n",
    "# We will not be able to provide alias for aggregated fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|FlightDate|count|\n",
      "+----------+-----+\n",
      "|2008-01-15|19204|\n",
      "|2008-01-21|19658|\n",
      "|2008-01-11|19825|\n",
      "|2008-01-19|15373|\n",
      "|2008-01-02|20442|\n",
      "|2008-01-06|19210|\n",
      "|2008-01-29|18596|\n",
      "|2008-01-30|19072|\n",
      "|2008-01-17|19401|\n",
      "|2008-01-31|19179|\n",
      "|2008-01-01|18623|\n",
      "|2008-01-24|19935|\n",
      "|2008-01-07|19762|\n",
      "|2008-01-09|19443|\n",
      "|2008-01-04|20160|\n",
      "|2008-01-08|19140|\n",
      "|2008-01-05|17610|\n",
      "|2008-01-25|19787|\n",
      "|2008-01-26|15860|\n",
      "|2008-01-12|16346|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airtraffic. \\\n",
    "    filter('Cancelled = 0'). \\\n",
    "    groupBy(concat(\"Year\", lit(\"-\"), \n",
    "                   lpad(\"Month\", 2, \"0\"), lit(\"-\"), \n",
    "                   lpad(\"DayOfMonth\", 2, \"0\")).\n",
    "            alias(\"FlightDate\")). \\\n",
    "    count(). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting total as well as delayed counts for each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum, expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+---------------+---------------+\n",
      "|FlightDate|FlightCount|DepDelayedCount|ArrDelayedCount|\n",
      "+----------+-----------+---------------+---------------+\n",
      "|2008-01-15|      19204|           5304|           6389|\n",
      "|2008-01-21|      19658|          10055|          11032|\n",
      "|2008-01-11|      19825|           7255|           8164|\n",
      "|2008-01-19|      15373|           6399|           6810|\n",
      "|2008-01-02|      20442|          13294|          13749|\n",
      "|2008-01-06|      19210|          10542|          10705|\n",
      "|2008-01-29|      18596|           6324|           8370|\n",
      "|2008-01-30|      19072|           6655|           7814|\n",
      "|2008-01-17|      19401|           9635|          11229|\n",
      "|2008-01-31|      19179|           9127|          11304|\n",
      "|2008-01-01|      18623|          10501|          11173|\n",
      "|2008-01-24|      19935|           8112|           9972|\n",
      "|2008-01-07|      19762|           8122|           8683|\n",
      "|2008-01-09|      19443|           5962|           6857|\n",
      "|2008-01-04|      20160|           9406|           9824|\n",
      "|2008-01-08|      19140|           7483|           8938|\n",
      "|2008-01-05|      17610|           9051|           9345|\n",
      "|2008-01-25|      19787|           8826|          10479|\n",
      "|2008-01-26|      15860|           5740|           7163|\n",
      "|2008-01-12|      16346|           3902|           4078|\n",
      "+----------+-----------+---------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airtraffic. \\\n",
    "    filter('Cancelled = 0'). \\\n",
    "    groupBy(concat(\"Year\", lit(\"-\"), \n",
    "                   lpad(\"Month\", 2, \"0\"), lit(\"-\"), \n",
    "                   lpad(\"DayOfMonth\", 2, \"0\")).\n",
    "            alias(\"FlightDate\")). \\\n",
    "    agg(count(lit(1)).alias(\"FlightCount\"),\n",
    "        sum(expr(\"CASE WHEN IsDepDelayed = 'YES' THEN 1 ELSE 0 END\")).alias(\"DepDelayedCount\"),\n",
    "        sum(expr(\"CASE WHEN IsArrDelayed = 'YES' THEN 1 ELSE 0 END\")).alias(\"ArrDelayedCount\")\n",
    "       ). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting Data By FlightDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method sort in module pyspark.sql.dataframe:\n",
      "\n",
      "sort(*cols, **kwargs) method of pyspark.sql.dataframe.DataFrame instance\n",
      "    Returns a new :class:`DataFrame` sorted by the specified column(s).\n",
      "    \n",
      "    :param cols: list of :class:`Column` or column names to sort by.\n",
      "    :param ascending: boolean or list of boolean (default ``True``).\n",
      "        Sort ascending vs. descending. Specify list for multiple sort orders.\n",
      "        If a list is specified, length of the list must equal length of the `cols`.\n",
      "    \n",
      "    >>> df.sort(df.age.desc()).collect()\n",
      "    [Row(age=5, name='Bob'), Row(age=2, name='Alice')]\n",
      "    >>> df.sort(\"age\", ascending=False).collect()\n",
      "    [Row(age=5, name='Bob'), Row(age=2, name='Alice')]\n",
      "    >>> df.orderBy(df.age.desc()).collect()\n",
      "    [Row(age=5, name='Bob'), Row(age=2, name='Alice')]\n",
      "    >>> from pyspark.sql.functions import *\n",
      "    >>> df.sort(asc(\"age\")).collect()\n",
      "    [Row(age=2, name='Alice'), Row(age=5, name='Bob')]\n",
      "    >>> df.orderBy(desc(\"age\"), \"name\").collect()\n",
      "    [Row(age=5, name='Bob'), Row(age=2, name='Alice')]\n",
      "    >>> df.orderBy([\"age\", \"name\"], ascending=[0, 1]).collect()\n",
      "    [Row(age=5, name='Bob'), Row(age=2, name='Alice')]\n",
      "    \n",
      "    .. versionadded:: 1.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(airtraffic.sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method sort in module pyspark.sql.dataframe:\n",
      "\n",
      "sort(*cols, **kwargs) method of pyspark.sql.dataframe.DataFrame instance\n",
      "    Returns a new :class:`DataFrame` sorted by the specified column(s).\n",
      "    \n",
      "    :param cols: list of :class:`Column` or column names to sort by.\n",
      "    :param ascending: boolean or list of boolean (default ``True``).\n",
      "        Sort ascending vs. descending. Specify list for multiple sort orders.\n",
      "        If a list is specified, length of the list must equal length of the `cols`.\n",
      "    \n",
      "    >>> df.sort(df.age.desc()).collect()\n",
      "    [Row(age=5, name='Bob'), Row(age=2, name='Alice')]\n",
      "    >>> df.sort(\"age\", ascending=False).collect()\n",
      "    [Row(age=5, name='Bob'), Row(age=2, name='Alice')]\n",
      "    >>> df.orderBy(df.age.desc()).collect()\n",
      "    [Row(age=5, name='Bob'), Row(age=2, name='Alice')]\n",
      "    >>> from pyspark.sql.functions import *\n",
      "    >>> df.sort(asc(\"age\")).collect()\n",
      "    [Row(age=2, name='Alice'), Row(age=5, name='Bob')]\n",
      "    >>> df.orderBy(desc(\"age\"), \"name\").collect()\n",
      "    [Row(age=5, name='Bob'), Row(age=2, name='Alice')]\n",
      "    >>> df.orderBy([\"age\", \"name\"], ascending=[0, 1]).collect()\n",
      "    [Row(age=5, name='Bob'), Row(age=2, name='Alice')]\n",
      "    \n",
      "    .. versionadded:: 1.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(airtraffic.orderBy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+---------------+---------------+\n",
      "|FlightDate|FlightCount|DepDelayedCount|ArrDelayedCount|\n",
      "+----------+-----------+---------------+---------------+\n",
      "|2008-01-01|      18623|          10501|          11173|\n",
      "|2008-01-02|      20442|          13294|          13749|\n",
      "|2008-01-03|      20462|          11819|          12013|\n",
      "|2008-01-04|      20160|           9406|           9824|\n",
      "|2008-01-05|      17610|           9051|           9345|\n",
      "|2008-01-06|      19210|          10542|          10705|\n",
      "|2008-01-07|      19762|           8122|           8683|\n",
      "|2008-01-08|      19140|           7483|           8938|\n",
      "|2008-01-09|      19443|           5962|           6857|\n",
      "|2008-01-10|      19956|           7033|           8565|\n",
      "|2008-01-11|      19825|           7255|           8164|\n",
      "|2008-01-12|      16346|           3902|           4078|\n",
      "|2008-01-13|      18587|           6634|           7473|\n",
      "|2008-01-14|      19267|           5921|           7104|\n",
      "|2008-01-15|      19204|           5304|           6389|\n",
      "|2008-01-16|      19232|           5102|           6228|\n",
      "|2008-01-17|      19401|           9635|          11229|\n",
      "|2008-01-18|      20117|          10038|          10860|\n",
      "|2008-01-19|      15373|           6399|           6810|\n",
      "|2008-01-20|      18406|           6700|           7005|\n",
      "|2008-01-21|      19658|          10055|          11032|\n",
      "|2008-01-22|      18716|           9129|          10669|\n",
      "|2008-01-23|      19239|           7349|           9324|\n",
      "|2008-01-24|      19935|           8112|           9972|\n",
      "|2008-01-25|      19787|           8826|          10479|\n",
      "|2008-01-26|      15860|           5740|           7163|\n",
      "|2008-01-27|      18265|           8905|          10331|\n",
      "|2008-01-28|      19493|           7580|           9013|\n",
      "|2008-01-29|      18596|           6324|           8370|\n",
      "|2008-01-30|      19072|           6655|           7814|\n",
      "|2008-01-31|      19179|           9127|          11304|\n",
      "+----------+-----------+---------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airtraffic. \\\n",
    "    filter('Cancelled = 0'). \\\n",
    "    groupBy(concat(\"Year\", lit(\"-\"), \n",
    "                   lpad(\"Month\", 2, \"0\"), lit(\"-\"), \n",
    "                   lpad(\"DayOfMonth\", 2, \"0\")).\n",
    "            alias(\"FlightDate\")). \\\n",
    "    agg(count(lit(1)).alias(\"FlightCount\"),\n",
    "        sum(expr(\"CASE WHEN IsDepDelayed = 'YES' THEN 1 ELSE 0 END\")).alias(\"DepDelayedCount\"),\n",
    "        sum(expr(\"CASE WHEN IsArrDelayed = 'YES' THEN 1 ELSE 0 END\")).alias(\"ArrDelayedCount\")\n",
    "       ). \\\n",
    "    orderBy(\"FlightDate\"). \\\n",
    "    show(31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting Data in descending order by count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+---------------+---------------+\n",
      "|FlightDate|FlightCount|DepDelayedCount|ArrDelayedCount|\n",
      "+----------+-----------+---------------+---------------+\n",
      "|2008-01-02|      20953|          13805|          14260|\n",
      "|2008-01-03|      20937|          12294|          12488|\n",
      "|2008-01-04|      20929|          10175|          10593|\n",
      "|2008-01-11|      20349|           7779|           8688|\n",
      "|2008-01-18|      20347|          10268|          11090|\n",
      "|2008-01-07|      20341|           8701|           9262|\n",
      "|2008-01-25|      20313|           9352|          11005|\n",
      "|2008-01-10|      20297|           7374|           8906|\n",
      "|2008-01-17|      20273|          10507|          12101|\n",
      "|2008-01-31|      20260|          10208|          12385|\n",
      "|2008-01-24|      20257|           8434|          10294|\n",
      "|2008-01-14|      20176|           6830|           8013|\n",
      "|2008-01-28|      20147|           8234|           9667|\n",
      "|2008-01-21|      20133|          10530|          11507|\n",
      "|2008-01-06|      19893|          11225|          11388|\n",
      "|2008-01-09|      19820|           6339|           7234|\n",
      "|2008-01-23|      19769|           7879|           9854|\n",
      "|2008-01-30|      19766|           7349|           8508|\n",
      "|2008-01-16|      19764|           5634|           6760|\n",
      "|2008-01-08|      19603|           7946|           9401|\n",
      "+----------+-----------+---------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit, concat, lpad, sum, expr, col\n",
    "airtraffic. \\\n",
    "    groupBy(concat(\"Year\", lit(\"-\"), \n",
    "                   lpad(\"Month\", 2, \"0\"), lit(\"-\"), \n",
    "                   lpad(\"DayOfMonth\", 2, \"0\")).\n",
    "            alias(\"FlightDate\")). \\\n",
    "    agg(count(lit(1)).alias(\"FlightCount\"),\n",
    "        sum(expr(\"CASE WHEN IsDepDelayed = 'YES' THEN 1 ELSE 0 END\")).alias(\"DepDelayedCount\"),\n",
    "        sum(expr(\"CASE WHEN IsArrDelayed = 'YES' THEN 1 ELSE 0 END\")).alias(\"ArrDelayedCount\")\n",
    "       ). \\\n",
    "    orderBy(col(\"FlightCount\").desc()). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 2",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
